{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVO2AJUdzxUSrq8QrOBPP8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PJunior17/pytorch_tutorial/blob/main/Procedural_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class LinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weights = nn.Parameter(torch.randn(1,\n",
        "                                            requires_grad=True,\n",
        "                                            dtype=torch.float))\n",
        "    self.bias = nn.Parameter(torch.randn(1,\n",
        "                                          requires_grad=True,\n",
        "                                          dtype=torch.float))\n",
        "  def forward(self, x):\n",
        "        return self.weights * x + self.bias\n",
        "\n",
        "def prepare_data():\n",
        "    #known parameters\n",
        "    weight = 0.7\n",
        "    bias = 0.3\n",
        "\n",
        "    #data\n",
        "    start = 0\n",
        "    end = 1\n",
        "    step = 0.02\n",
        "    X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
        "    y = weight * X + bias\n",
        "\n",
        "    train_split = int(0.8 * len(X))\n",
        "    X_train, y_train = X[:train_split], y[:train_split]\n",
        "    X_test, y_test = X[train_split:], y[train_split:]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "def train_model(model, X_train, y_train, X_test, y_test):\n",
        "    torch.manual_seed(42)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "    loss_fn = nn.L1Loss()\n",
        "    epochs = 1000\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        y_pred = model(X_train)\n",
        "        loss = loss_fn(y_pred, y_train)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            test_pred = model(X_test)\n",
        "            test_loss = loss_fn(test_pred, y_test)\n",
        "        print('Epoch: %s | Training Loss: %s | Test Loss: %s' %(epoch, loss, test_loss))\n",
        "\n",
        "def main():\n",
        "    X_train, y_train, X_test, y_test = prepare_data()\n",
        "    model = LinearRegressionModel()\n",
        "    train_model(model, X_train, y_train, X_test, y_test)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yHiY31-oXRS",
        "outputId": "dc5eb4eb-8706-4f2a-93b3-ae65de6f68b4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Training Loss: tensor(0.3129, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.4811)\n",
            "Epoch: 1 | Training Loss: tensor(0.3014, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.4676)\n",
            "Epoch: 2 | Training Loss: tensor(0.2898, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.4541)\n",
            "Epoch: 3 | Training Loss: tensor(0.2783, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.4407)\n",
            "Epoch: 4 | Training Loss: tensor(0.2668, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.4272)\n",
            "Epoch: 5 | Training Loss: tensor(0.2553, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.4137)\n",
            "Epoch: 6 | Training Loss: tensor(0.2438, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.4002)\n",
            "Epoch: 7 | Training Loss: tensor(0.2322, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.3868)\n",
            "Epoch: 8 | Training Loss: tensor(0.2207, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.3733)\n",
            "Epoch: 9 | Training Loss: tensor(0.2092, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.3598)\n",
            "Epoch: 10 | Training Loss: tensor(0.1977, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.3464)\n",
            "Epoch: 11 | Training Loss: tensor(0.1862, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.3329)\n",
            "Epoch: 12 | Training Loss: tensor(0.1746, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.3194)\n",
            "Epoch: 13 | Training Loss: tensor(0.1631, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.3059)\n",
            "Epoch: 14 | Training Loss: tensor(0.1516, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.2925)\n",
            "Epoch: 15 | Training Loss: tensor(0.1401, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.2790)\n",
            "Epoch: 16 | Training Loss: tensor(0.1285, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.2655)\n",
            "Epoch: 17 | Training Loss: tensor(0.1170, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.2521)\n",
            "Epoch: 18 | Training Loss: tensor(0.1061, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.2396)\n",
            "Epoch: 19 | Training Loss: tensor(0.0968, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.2282)\n",
            "Epoch: 20 | Training Loss: tensor(0.0891, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.2173)\n",
            "Epoch: 21 | Training Loss: tensor(0.0823, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.2070)\n",
            "Epoch: 22 | Training Loss: tensor(0.0764, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1977)\n",
            "Epoch: 23 | Training Loss: tensor(0.0716, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1891)\n",
            "Epoch: 24 | Training Loss: tensor(0.0675, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1810)\n",
            "Epoch: 25 | Training Loss: tensor(0.0640, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1735)\n",
            "Epoch: 26 | Training Loss: tensor(0.0610, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1667)\n",
            "Epoch: 27 | Training Loss: tensor(0.0585, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1604)\n",
            "Epoch: 28 | Training Loss: tensor(0.0564, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1547)\n",
            "Epoch: 29 | Training Loss: tensor(0.0546, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1497)\n",
            "Epoch: 30 | Training Loss: tensor(0.0531, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1446)\n",
            "Epoch: 31 | Training Loss: tensor(0.0518, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1402)\n",
            "Epoch: 32 | Training Loss: tensor(0.0507, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1365)\n",
            "Epoch: 33 | Training Loss: tensor(0.0498, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1327)\n",
            "Epoch: 34 | Training Loss: tensor(0.0490, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1290)\n",
            "Epoch: 35 | Training Loss: tensor(0.0482, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1258)\n",
            "Epoch: 36 | Training Loss: tensor(0.0475, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1227)\n",
            "Epoch: 37 | Training Loss: tensor(0.0469, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1203)\n",
            "Epoch: 38 | Training Loss: tensor(0.0464, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1178)\n",
            "Epoch: 39 | Training Loss: tensor(0.0459, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1154)\n",
            "Epoch: 40 | Training Loss: tensor(0.0454, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1136)\n",
            "Epoch: 41 | Training Loss: tensor(0.0450, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1118)\n",
            "Epoch: 42 | Training Loss: tensor(0.0446, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1100)\n",
            "Epoch: 43 | Training Loss: tensor(0.0442, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1083)\n",
            "Epoch: 44 | Training Loss: tensor(0.0438, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1065)\n",
            "Epoch: 45 | Training Loss: tensor(0.0434, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1047)\n",
            "Epoch: 46 | Training Loss: tensor(0.0431, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1036)\n",
            "Epoch: 47 | Training Loss: tensor(0.0427, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1025)\n",
            "Epoch: 48 | Training Loss: tensor(0.0424, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1014)\n",
            "Epoch: 49 | Training Loss: tensor(0.0420, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.1003)\n",
            "Epoch: 50 | Training Loss: tensor(0.0417, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0992)\n",
            "Epoch: 51 | Training Loss: tensor(0.0413, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0981)\n",
            "Epoch: 52 | Training Loss: tensor(0.0410, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0970)\n",
            "Epoch: 53 | Training Loss: tensor(0.0406, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0959)\n",
            "Epoch: 54 | Training Loss: tensor(0.0403, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0948)\n",
            "Epoch: 55 | Training Loss: tensor(0.0399, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0937)\n",
            "Epoch: 56 | Training Loss: tensor(0.0396, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0926)\n",
            "Epoch: 57 | Training Loss: tensor(0.0392, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0915)\n",
            "Epoch: 58 | Training Loss: tensor(0.0389, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0904)\n",
            "Epoch: 59 | Training Loss: tensor(0.0385, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0893)\n",
            "Epoch: 60 | Training Loss: tensor(0.0382, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0889)\n",
            "Epoch: 61 | Training Loss: tensor(0.0379, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0878)\n",
            "Epoch: 62 | Training Loss: tensor(0.0375, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0867)\n",
            "Epoch: 63 | Training Loss: tensor(0.0372, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0862)\n",
            "Epoch: 64 | Training Loss: tensor(0.0368, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0851)\n",
            "Epoch: 65 | Training Loss: tensor(0.0365, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0847)\n",
            "Epoch: 66 | Training Loss: tensor(0.0361, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0836)\n",
            "Epoch: 67 | Training Loss: tensor(0.0358, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0832)\n",
            "Epoch: 68 | Training Loss: tensor(0.0354, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0821)\n",
            "Epoch: 69 | Training Loss: tensor(0.0351, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0810)\n",
            "Epoch: 70 | Training Loss: tensor(0.0348, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0806)\n",
            "Epoch: 71 | Training Loss: tensor(0.0344, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0795)\n",
            "Epoch: 72 | Training Loss: tensor(0.0341, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0791)\n",
            "Epoch: 73 | Training Loss: tensor(0.0337, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0780)\n",
            "Epoch: 74 | Training Loss: tensor(0.0334, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0776)\n",
            "Epoch: 75 | Training Loss: tensor(0.0330, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0765)\n",
            "Epoch: 76 | Training Loss: tensor(0.0327, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0754)\n",
            "Epoch: 77 | Training Loss: tensor(0.0324, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0749)\n",
            "Epoch: 78 | Training Loss: tensor(0.0320, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0738)\n",
            "Epoch: 79 | Training Loss: tensor(0.0317, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0734)\n",
            "Epoch: 80 | Training Loss: tensor(0.0313, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0723)\n",
            "Epoch: 81 | Training Loss: tensor(0.0310, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0719)\n",
            "Epoch: 82 | Training Loss: tensor(0.0306, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0708)\n",
            "Epoch: 83 | Training Loss: tensor(0.0303, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0704)\n",
            "Epoch: 84 | Training Loss: tensor(0.0300, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0693)\n",
            "Epoch: 85 | Training Loss: tensor(0.0296, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0682)\n",
            "Epoch: 86 | Training Loss: tensor(0.0293, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0678)\n",
            "Epoch: 87 | Training Loss: tensor(0.0289, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0667)\n",
            "Epoch: 88 | Training Loss: tensor(0.0286, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0663)\n",
            "Epoch: 89 | Training Loss: tensor(0.0282, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0652)\n",
            "Epoch: 90 | Training Loss: tensor(0.0279, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0647)\n",
            "Epoch: 91 | Training Loss: tensor(0.0275, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0636)\n",
            "Epoch: 92 | Training Loss: tensor(0.0272, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0625)\n",
            "Epoch: 93 | Training Loss: tensor(0.0269, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0621)\n",
            "Epoch: 94 | Training Loss: tensor(0.0265, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0610)\n",
            "Epoch: 95 | Training Loss: tensor(0.0262, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0606)\n",
            "Epoch: 96 | Training Loss: tensor(0.0258, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0595)\n",
            "Epoch: 97 | Training Loss: tensor(0.0255, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0591)\n",
            "Epoch: 98 | Training Loss: tensor(0.0251, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0580)\n",
            "Epoch: 99 | Training Loss: tensor(0.0248, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0569)\n",
            "Epoch: 100 | Training Loss: tensor(0.0245, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0565)\n",
            "Epoch: 101 | Training Loss: tensor(0.0241, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0554)\n",
            "Epoch: 102 | Training Loss: tensor(0.0238, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0549)\n",
            "Epoch: 103 | Training Loss: tensor(0.0234, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0538)\n",
            "Epoch: 104 | Training Loss: tensor(0.0231, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0534)\n",
            "Epoch: 105 | Training Loss: tensor(0.0227, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0523)\n",
            "Epoch: 106 | Training Loss: tensor(0.0224, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0519)\n",
            "Epoch: 107 | Training Loss: tensor(0.0221, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0508)\n",
            "Epoch: 108 | Training Loss: tensor(0.0217, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0497)\n",
            "Epoch: 109 | Training Loss: tensor(0.0214, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0493)\n",
            "Epoch: 110 | Training Loss: tensor(0.0210, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0482)\n",
            "Epoch: 111 | Training Loss: tensor(0.0207, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0478)\n",
            "Epoch: 112 | Training Loss: tensor(0.0203, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0467)\n",
            "Epoch: 113 | Training Loss: tensor(0.0200, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0463)\n",
            "Epoch: 114 | Training Loss: tensor(0.0196, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0452)\n",
            "Epoch: 115 | Training Loss: tensor(0.0193, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0441)\n",
            "Epoch: 116 | Training Loss: tensor(0.0190, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0436)\n",
            "Epoch: 117 | Training Loss: tensor(0.0186, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0425)\n",
            "Epoch: 118 | Training Loss: tensor(0.0183, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0421)\n",
            "Epoch: 119 | Training Loss: tensor(0.0179, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0410)\n",
            "Epoch: 120 | Training Loss: tensor(0.0176, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0406)\n",
            "Epoch: 121 | Training Loss: tensor(0.0172, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0395)\n",
            "Epoch: 122 | Training Loss: tensor(0.0169, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0391)\n",
            "Epoch: 123 | Training Loss: tensor(0.0166, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0380)\n",
            "Epoch: 124 | Training Loss: tensor(0.0162, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0369)\n",
            "Epoch: 125 | Training Loss: tensor(0.0159, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0365)\n",
            "Epoch: 126 | Training Loss: tensor(0.0155, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0354)\n",
            "Epoch: 127 | Training Loss: tensor(0.0152, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0350)\n",
            "Epoch: 128 | Training Loss: tensor(0.0148, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0338)\n",
            "Epoch: 129 | Training Loss: tensor(0.0145, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0334)\n",
            "Epoch: 130 | Training Loss: tensor(0.0142, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0323)\n",
            "Epoch: 131 | Training Loss: tensor(0.0138, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0312)\n",
            "Epoch: 132 | Training Loss: tensor(0.0135, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0308)\n",
            "Epoch: 133 | Training Loss: tensor(0.0131, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0297)\n",
            "Epoch: 134 | Training Loss: tensor(0.0128, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0293)\n",
            "Epoch: 135 | Training Loss: tensor(0.0124, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0282)\n",
            "Epoch: 136 | Training Loss: tensor(0.0121, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0278)\n",
            "Epoch: 137 | Training Loss: tensor(0.0118, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0267)\n",
            "Epoch: 138 | Training Loss: tensor(0.0114, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0256)\n",
            "Epoch: 139 | Training Loss: tensor(0.0111, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0252)\n",
            "Epoch: 140 | Training Loss: tensor(0.0107, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0241)\n",
            "Epoch: 141 | Training Loss: tensor(0.0104, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0236)\n",
            "Epoch: 142 | Training Loss: tensor(0.0100, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0225)\n",
            "Epoch: 143 | Training Loss: tensor(0.0097, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0221)\n",
            "Epoch: 144 | Training Loss: tensor(0.0093, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0210)\n",
            "Epoch: 145 | Training Loss: tensor(0.0090, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0206)\n",
            "Epoch: 146 | Training Loss: tensor(0.0087, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0195)\n",
            "Epoch: 147 | Training Loss: tensor(0.0083, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0184)\n",
            "Epoch: 148 | Training Loss: tensor(0.0080, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0180)\n",
            "Epoch: 149 | Training Loss: tensor(0.0076, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0169)\n",
            "Epoch: 150 | Training Loss: tensor(0.0073, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0165)\n",
            "Epoch: 151 | Training Loss: tensor(0.0069, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0154)\n",
            "Epoch: 152 | Training Loss: tensor(0.0066, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0150)\n",
            "Epoch: 153 | Training Loss: tensor(0.0063, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0139)\n",
            "Epoch: 154 | Training Loss: tensor(0.0059, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0128)\n",
            "Epoch: 155 | Training Loss: tensor(0.0056, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0123)\n",
            "Epoch: 156 | Training Loss: tensor(0.0052, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0112)\n",
            "Epoch: 157 | Training Loss: tensor(0.0049, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0108)\n",
            "Epoch: 158 | Training Loss: tensor(0.0045, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0097)\n",
            "Epoch: 159 | Training Loss: tensor(0.0042, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0093)\n",
            "Epoch: 160 | Training Loss: tensor(0.0039, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0082)\n",
            "Epoch: 161 | Training Loss: tensor(0.0035, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0071)\n",
            "Epoch: 162 | Training Loss: tensor(0.0032, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0067)\n",
            "Epoch: 163 | Training Loss: tensor(0.0028, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0056)\n",
            "Epoch: 164 | Training Loss: tensor(0.0025, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0052)\n",
            "Epoch: 165 | Training Loss: tensor(0.0021, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0041)\n",
            "Epoch: 166 | Training Loss: tensor(0.0018, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0037)\n",
            "Epoch: 167 | Training Loss: tensor(0.0015, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0019)\n",
            "Epoch: 168 | Training Loss: tensor(0.0012, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 169 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 170 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 171 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 172 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 173 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 174 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 175 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 176 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 177 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 178 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 179 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 180 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 181 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 182 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 183 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 184 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 185 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 186 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 187 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 188 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 189 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 190 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 191 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 192 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 193 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 194 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 195 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 196 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 197 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 198 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 199 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 200 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 201 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 202 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 203 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 204 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 205 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 206 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 207 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 208 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 209 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 210 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 211 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 212 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 213 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 214 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 215 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 216 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 217 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 218 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 219 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 220 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 221 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 222 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 223 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 224 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 225 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 226 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 227 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 228 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 229 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 230 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 231 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 232 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 233 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 234 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 235 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 236 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 237 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 238 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 239 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 240 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 241 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 242 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 243 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 244 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 245 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 246 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 247 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 248 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 249 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 250 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 251 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 252 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 253 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 254 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 255 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 256 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 257 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 258 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 259 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 260 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 261 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 262 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 263 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 264 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 265 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 266 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 267 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 268 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 269 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 270 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 271 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 272 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 273 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 274 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 275 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 276 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 277 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 278 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 279 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 280 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 281 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 282 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 283 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 284 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 285 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 286 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 287 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 288 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 289 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 290 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 291 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 292 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 293 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 294 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 295 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 296 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 297 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 298 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 299 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 300 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 301 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 302 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 303 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 304 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 305 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 306 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 307 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 308 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 309 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 310 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 311 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 312 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 313 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 314 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 315 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 316 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 317 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 318 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 319 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 320 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 321 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 322 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 323 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 324 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 325 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 326 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 327 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 328 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 329 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 330 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 331 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 332 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 333 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 334 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 335 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 336 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 337 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 338 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 339 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 340 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 341 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 342 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 343 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 344 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 345 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 346 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 347 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 348 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 349 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 350 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 351 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 352 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 353 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 354 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 355 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 356 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 357 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 358 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 359 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 360 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 361 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 362 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 363 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 364 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 365 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 366 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 367 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 368 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 369 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 370 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 371 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 372 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 373 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 374 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 375 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 376 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 377 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 378 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 379 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 380 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 381 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 382 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 383 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 384 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 385 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 386 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 387 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 388 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 389 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 390 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 391 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 392 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 393 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 394 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 395 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 396 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 397 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 398 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 399 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 400 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 401 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 402 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 403 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 404 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 405 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 406 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 407 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 408 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 409 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 410 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 411 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 412 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 413 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 414 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 415 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 416 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 417 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 418 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 419 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 420 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 421 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 422 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 423 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 424 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 425 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 426 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 427 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 428 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 429 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 430 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 431 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 432 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 433 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 434 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 435 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 436 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 437 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 438 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 439 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 440 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 441 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 442 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 443 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 444 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 445 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 446 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 447 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 448 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 449 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 450 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 451 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 452 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 453 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 454 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 455 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 456 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 457 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 458 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 459 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 460 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 461 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 462 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 463 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 464 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 465 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 466 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 467 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 468 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 469 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 470 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 471 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 472 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 473 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 474 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 475 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 476 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 477 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 478 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 479 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 480 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 481 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 482 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 483 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 484 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 485 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 486 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 487 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 488 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 489 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 490 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 491 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 492 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 493 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 494 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 495 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 496 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 497 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 498 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 499 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 500 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 501 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 502 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 503 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 504 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 505 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 506 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 507 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 508 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 509 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 510 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 511 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 512 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 513 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 514 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 515 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 516 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 517 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 518 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 519 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 520 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 521 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 522 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 523 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 524 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 525 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 526 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 527 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 528 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 529 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 530 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 531 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 532 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 533 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 534 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 535 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 536 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 537 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 538 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 539 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 540 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 541 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 542 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 543 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 544 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 545 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 546 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 547 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 548 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 549 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 550 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 551 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 552 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 553 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 554 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 555 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 556 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 557 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 558 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 559 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 560 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 561 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 562 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 563 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 564 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 565 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 566 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 567 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 568 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 569 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 570 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 571 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 572 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 573 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 574 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 575 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 576 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 577 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 578 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 579 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 580 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 581 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 582 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 583 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 584 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 585 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 586 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 587 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 588 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 589 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 590 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 591 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 592 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 593 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 594 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 595 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 596 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 597 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 598 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 599 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 600 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 601 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 602 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 603 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 604 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 605 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 606 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 607 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 608 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 609 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 610 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 611 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 612 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 613 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 614 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 615 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 616 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 617 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 618 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 619 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 620 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 621 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 622 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 623 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 624 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 625 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 626 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 627 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 628 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 629 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 630 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 631 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 632 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 633 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 634 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 635 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 636 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 637 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 638 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 639 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 640 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 641 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 642 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 643 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 644 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 645 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 646 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 647 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 648 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 649 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 650 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 651 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 652 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 653 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 654 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 655 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 656 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 657 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 658 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 659 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 660 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 661 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 662 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 663 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 664 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 665 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 666 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 667 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 668 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 669 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 670 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 671 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 672 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 673 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 674 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 675 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 676 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 677 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 678 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 679 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 680 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 681 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 682 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 683 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 684 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 685 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 686 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 687 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 688 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 689 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 690 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 691 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 692 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 693 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 694 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 695 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 696 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 697 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 698 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 699 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 700 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 701 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 702 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 703 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 704 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 705 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 706 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 707 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 708 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 709 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 710 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 711 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 712 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 713 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 714 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 715 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 716 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 717 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 718 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 719 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 720 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 721 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 722 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 723 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 724 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 725 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 726 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 727 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 728 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 729 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 730 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 731 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 732 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 733 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 734 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 735 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 736 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 737 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 738 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 739 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 740 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 741 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 742 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 743 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 744 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 745 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 746 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 747 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 748 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 749 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 750 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 751 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 752 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 753 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 754 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 755 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 756 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 757 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 758 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 759 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 760 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 761 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 762 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 763 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 764 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 765 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 766 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 767 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 768 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 769 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 770 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 771 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 772 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 773 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 774 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 775 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 776 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 777 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 778 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 779 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 780 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 781 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 782 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 783 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 784 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 785 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 786 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 787 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 788 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 789 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 790 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 791 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 792 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 793 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 794 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 795 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 796 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 797 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 798 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 799 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 800 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 801 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 802 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 803 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 804 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 805 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 806 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 807 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 808 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 809 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 810 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 811 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 812 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 813 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 814 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 815 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 816 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 817 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 818 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 819 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 820 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 821 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 822 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 823 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 824 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 825 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 826 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 827 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 828 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 829 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 830 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 831 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 832 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 833 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 834 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 835 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 836 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 837 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 838 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 839 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 840 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 841 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 842 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 843 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 844 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 845 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 846 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 847 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 848 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 849 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 850 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 851 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 852 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 853 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 854 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 855 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 856 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 857 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 858 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 859 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 860 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 861 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 862 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 863 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 864 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 865 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 866 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 867 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 868 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 869 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 870 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 871 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 872 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 873 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 874 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 875 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 876 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 877 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 878 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 879 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 880 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 881 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 882 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 883 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 884 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 885 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 886 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 887 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 888 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 889 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 890 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 891 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 892 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 893 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 894 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 895 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 896 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 897 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 898 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 899 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 900 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 901 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 902 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 903 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 904 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 905 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 906 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 907 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 908 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 909 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 910 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 911 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 912 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 913 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 914 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 915 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 916 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 917 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 918 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 919 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 920 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 921 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 922 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 923 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 924 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 925 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 926 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 927 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 928 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 929 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 930 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 931 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 932 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 933 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 934 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 935 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 936 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 937 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 938 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 939 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 940 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 941 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 942 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 943 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 944 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 945 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 946 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 947 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 948 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 949 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 950 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 951 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 952 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 953 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 954 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 955 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 956 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 957 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 958 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 959 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 960 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 961 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 962 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 963 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 964 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 965 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 966 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 967 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 968 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 969 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 970 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 971 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 972 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 973 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 974 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 975 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 976 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 977 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 978 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 979 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 980 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 981 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 982 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 983 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 984 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 985 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 986 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 987 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 988 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 989 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 990 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 991 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 992 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 993 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 994 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 995 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 996 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 997 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n",
            "Epoch: 998 | Training Loss: tensor(0.0089, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0050)\n",
            "Epoch: 999 | Training Loss: tensor(0.0026, grad_fn=<MeanBackward0>) | Test Loss: tensor(0.0084)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LsD4HR0sofVR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}